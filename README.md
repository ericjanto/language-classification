## Language detection experiment
This project involved building a character-level language model using the Brown corpus, utilising the `LgramModel` from `nltk_model` which builds n-grams from characters rather than words. In addition to the Brown corpus, we used a small snapshot of data generated by users of Twitter in a form of tweets.

The model was trained to distinguish English tweets from non-English tweets.

## Setup
You can create a virtual env using conda. For this you need
anaconda installed in your system. A recommended configuration
is to set the automatic activation of the `base` env to false,
running:

```
conda config --set auto_activate_base False
```

Using the `enviroment.yml` you can create the new env.

1. Create the environment using:
   ```
   conda env create -f environment.yml
   ```
1. Activate the environment
   ```
   conda activate fnlp
   ```


Update / add packages:

1. conda activate fnlp
2. conda install --name fnlp <package> -y
3. conda env export > environment.yml
